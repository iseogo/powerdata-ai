import streamlit as st
import time

st.markdown("""
# üëã Welcome to Powerdata.ai
Your all-in-one workspace to analyze, visualize, and model data ‚Äî using just natural language.
""")

with st.spinner("Loading your AI workspace..."):
    time.sleep(1)

st.success("Ready! Choose your task below.")

# Text or Voice Input Box

# ‚úÖ Updated OpenAI ChatCompletion block
import openai
openai.api_key = st.secrets["OPENAI_API_KEY"]

user_prompt = st.text_input("Ask something about your data (type or speak):", "What does the data say about sales?")
if user_prompt:
    if "qa_history" not in st.session_state:
        st.session_state.qa_history = []
    try:
        with st.spinner("Generating AI response..."):
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful data analyst. If a dataset is uploaded, use it to answer the user's request."},
                    {"role": "user", "content": f"{user_prompt}

Here is a sample of the uploaded data:
{df.head(10).to_string(index=False) if 'df' in locals() else 'No dataset uploaded.'}"}
                ]
            )
            reply = response.choices[0].message.content
            st.session_state.qa_history.append((user_prompt, reply))
            st.markdown(f"**AI Response:**
{reply}")
    except Exception as e:
        st.error(f"‚ö†Ô∏è Error: {str(e)}")
    if 'df' not in locals():
        st.warning("‚ö†Ô∏è No dataset uploaded yet. AI responses may be generic.")
    else:
        csv_data = df.to_csv(index=False).encode('utf-8')
        st.download_button("üì• Download Your Uploaded Dataset", csv_data, file_name="uploaded_dataset.csv")
{reply}")
st.markdown("## üßæ Conversation History")
if "qa_history" in st.session_state:
    for i, (q, a) in enumerate(st.session_state.qa_history, 1):
        st.markdown(f"**Q{i}:** {q}")
        st.markdown(f"**A{i}:** {a}")

st.markdown("## üó£Ô∏è Ask Questions or Make a Request")
st.markdown("Use the text box below, or click the microphone icon to speak.")

st.markdown("""
<script>
function startDictation() {
    if (window.hasOwnProperty('webkitSpeechRecognition')) {
        var recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = "en-US";
        recognition.start();

        recognition.onresult = function(e) {
            document.getElementById('voiceInput').value = e.results[0][0].transcript;
            recognition.stop();
        };

        recognition.onerror = function(e) {
            recognition.stop();
        }
    }
}
</script>
<input id='voiceInput' name='voiceInput' placeholder='Click mic or type here...' style='width: 80%; height: 30px;'>
<button onclick='startDictation()'>üé§</button>
""", unsafe_allow_html=True)

task_options = [
    "Dashboards" ,
    "Data Analysis Workflow",
    "Business Analysis Workflow",
    "Data Science Workflow",
    "Data Analytics Workflow",
    "Reinforcement Learning (Advanced)",
    "Semi-Supervised Learning (Partial Labels)",
    "Unsupervised Learning (Clustering & Dimensionality Reduction)",
    "Supervised Learning (Classification & Regression)",
    "Descriptive Statistics",
    "Deep Learning Trainer",
    "Natural Language Processing (NLP)",
    "Image Recognition",
    "Speech-to-Text",
    "Time Series Analysis"
]
task_selection = st.selectbox("Choose a task to explore:", task_options)

report_template = lambda title, summary, steps, insights, conclusion: f"""
## üìÑ {title} Report

### üîç Summary
{summary}

### üìä Analysis Steps
{steps}

### üìà Key Insights
{insights}

### ‚úÖ Conclusion
{conclusion}
"""

if task_selection == "Machine Learning (Classification & Regression)":
    with st.container():
        st.subheader("üìò Supervised Learning")
        st.caption("Upload a CSV file and select features and target for classification or regression.")
        ml_file = st.file_uploader("Upload dataset", type="csv", key="ml")
        if ml_file:
            import pandas as pd
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import LabelEncoder, StandardScaler
            from sklearn.metrics import accuracy_score, mean_squared_error
            from sklearn.linear_model import LogisticRegression, LinearRegression
            from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
            import matplotlib.pyplot as plt
            import seaborn as sns

            df = pd.read_csv(ml_file)
            st.dataframe(df.head())
        chart_col = st.selectbox("Select column to chart:", df.select_dtypes("number").columns.tolist(), index=0)
        plot_type = st.radio("Chart type:", ["Histogram", "Scatter", "Line"])
        fig, ax = plt.subplots()
        if plot_type == "Histogram":
            df[chart_col].hist(bins=30, ax=ax)
            ax.set_title(f"Histogram of {chart_col}")
        elif plot_type == "Scatter":
            if len(df.select_dtypes("number").columns) >= 2:
                x_col = st.selectbox("X-axis:", df.select_dtypes("number").columns.tolist(), index=0)
                y_col = st.selectbox("Y-axis:", [col for col in df.select_dtypes("number").columns if col != x_col], index=0)
                ax.scatter(df[x_col], df[y_col])
                ax.set_xlabel(x_col)
                ax.set_ylabel(y_col)
                ax.set_title(f"Scatter Plot: {y_col} vs {x_col}")
            else:
                st.warning("Need at least 2 numeric columns for scatter plot.")
        elif plot_type == "Line":
            ax.plot(df[chart_col])
            ax.set_title(f"Line Plot of {chart_col}")
        st.pyplot(fig)
        import io
        chart_buf = io.BytesIO()
        fig.savefig(chart_buf, format='png')
        chart_buf.seek(0)
        st.download_button("üì∏ Download Chart Image", chart_buf.read(), file_name="chart_visual.png")
            import matplotlib.pyplot as plt
            chart_col = 'price' if 'price' in df.columns else 'sales'
            fig, ax = plt.subplots()
            df[chart_col].hist(bins=30, ax=ax)
            ax.set_title(f"Histogram of {chart_col}")
            st.pyplot(fig)
            task_type = st.radio("Choose task:", ["Classification", "Regression"])
            target = st.selectbox("Select target column:", df.columns)
            features = st.multiselect("Select feature columns:", [col for col in df.columns if col != target])

            if target and features:
                X = df[features]
                y = df[target]
                if y.dtype == 'object':
                    y = LabelEncoder().fit_transform(y)
                X = pd.get_dummies(X)
                X = StandardScaler().fit_transform(X)
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                if task_type == "Classification":
                    model = st.selectbox("Model:", ["Logistic Regression", "Random Forest Classifier"])
                    if model == "Logistic Regression":
                        clf = LogisticRegression()
                    else:
                        clf = RandomForestClassifier()
                    clf.fit(X_train, y_train)
                    import joblib
                    joblib.dump(clf, "ml_model.pkl")
                    with open("ml_model.pkl", "rb") as f:
                        st.download_button("üì• Download Trained Model", f.read(), file_name="ml_model.pkl")
                    preds = clf.predict(X_test)
                    acc = accuracy_score(y_test, preds)
                    st.success(f"Accuracy: {acc:.2%}")
                else:
                    model = st.selectbox("Model:", ["Linear Regression", "Random Forest Regressor"])
                    if model == "Linear Regression":
                        clf = LinearRegression()
                    else:
                        clf = RandomForestRegressor()
                    clf.fit(X_train, y_train)
                    preds = clf.predict(X_test)
                    rmse = mean_squared_error(y_test, preds, squared=False)
                    st.success(f"RMSE: {rmse:.2f}")

                    fig, ax = plt.subplots()
                    ax.scatter(y_test, preds, alpha=0.6)
                    ax.set_xlabel("Actual")
                    ax.set_ylabel("Predicted")
                    ax.set_title("Regression: Actual vs Predicted")
                    st.pyplot(fig)

        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Unsupervised Learning (Clustering & Dimensionality Reduction)":
    with st.container():
        st.subheader("üìô Unsupervised Learning")
        st.caption("Upload a CSV file to perform clustering (KMeans) or dimensionality reduction (PCA).")
        unsup_file = st.file_uploader("Upload dataset", type="csv", key="unsup")
        if unsup_file:
            import pandas as pd
            import matplotlib.pyplot as plt
            from sklearn.preprocessing import StandardScaler
            from sklearn.decomposition import PCA
            from sklearn.cluster import KMeans

            df = pd.read_csv(unsup_file)
            st.dataframe(df.head())
            df_clean = df.select_dtypes(include='number').dropna()
            X = StandardScaler().fit_transform(df_clean)
            st.write("### Choose Technique")
            unsup_task = st.radio("Task:", ["Clustering (KMeans)", "Dimensionality Reduction (PCA)"])

            if unsup_task == "Clustering (KMeans)":
                k = st.slider("Number of clusters (k):", 2, 10, 3)
                model = KMeans(n_clusters=k, random_state=42)
                labels = model.fit_predict(X)
                df['Cluster'] = labels
                st.dataframe(df[['Cluster']].join(df_clean))

                cluster_csv = df[['Cluster']].join(df_clean).to_csv(index=False).encode('utf-8')
                st.download_button("üì• Download Cluster Results", cluster_csv, file_name="kmeans_clusters.csv")

                pca = PCA(n_components=2)
                reduced = pca.fit_transform(X)
                fig, ax = plt.subplots()
                scatter = ax.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='viridis')
                ax.set_title("KMeans Clustering (2D PCA Projection)")
                st.pyplot(fig)

            else:
                components = st.slider("PCA components:", 2, min(10, X.shape[1]), 2)
                pca = PCA(n_components=components)
                reduced = pca.fit_transform(X)
                reduced_df = pd.DataFrame(reduced, columns=[f"PC{i+1}" for i in range(components)])
                st.dataframe(reduced_df)
                pca_csv = reduced_df.to_csv(index=False).encode('utf-8')
                st.download_button("üì• Download PCA Results", pca_csv, file_name="pca_components.csv")

                fig, ax = plt.subplots()
                ax.plot(range(1, components+1), pca.explained_variance_ratio_, marker='o')
                ax.set_title("Explained Variance per Component")
                ax.set_xlabel("Principal Component")
                ax.set_ylabel("Variance Ratio")
                st.pyplot(fig)

        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Semi-Supervised Learning (Partial Labels)":
    with st.container():
        st.subheader("üß™ Semi-Supervised Learning")
        st.caption("Upload a CSV with a partially labeled target column. We'll use SelfTrainingClassifier or LabelSpreading.")
        semi_file = st.file_uploader("Upload dataset", type="csv", key="semi")
        if semi_file:
            import pandas as pd
            from sklearn.preprocessing import LabelEncoder, StandardScaler
            from sklearn.semi_supervised import SelfTrainingClassifier, LabelSpreading
            from sklearn.linear_model import LogisticRegression
            from sklearn.model_selection import train_test_split
            import numpy as np

            df = pd.read_csv(semi_file)
            st.dataframe(df.head())
            target = st.selectbox("Select target column:", df.columns)
            features = st.multiselect("Select feature columns:", [col for col in df.columns if col != target])

            if target and features:
                df[target] = df[target].replace("", np.nan)
                df_labeled = df.dropna(subset=[target])
                df_unlabeled = df[df[target].isna()]
                st.write(f"Labeled samples: {len(df_labeled)}, Unlabeled samples: {len(df_unlabeled)}")

                X_all = pd.get_dummies(df[features])
                y_all = df[target]
                y_all = LabelEncoder().fit_transform(y_all.fillna(-1).astype(str))
                X_all = StandardScaler().fit_transform(X_all)

                algo = st.radio("Choose method:", ["SelfTrainingClassifier", "LabelSpreading"])
                if algo == "SelfTrainingClassifier":
                    base = LogisticRegression()
                    model = SelfTrainingClassifier(base)
                else:
                    model = LabelSpreading()

                model.fit(X_all, y_all)
                y_pred = model.transduction_

                df_result = df.copy()
                df_result['Predicted_Label'] = y_pred
                st.dataframe(df_result[[target] + ['Predicted_Label'] + features])

                import matplotlib.pyplot as plt
                import seaborn as sns
                fig, ax = plt.subplots()
                sns.countplot(data=df_result, x='Predicted_Label', hue=target, ax=ax)
                img = io.BytesIO()
                fig.savefig(img, format='png')
                img.seek(0)
                st.download_button("üì∏ Download Prediction Plot", img.read(), file_name="semi_supervised_plot.png")
                ax.set_title("Predicted vs Known Labels")
                st.pyplot(fig)
                csv = df_result.to_csv(index=False).encode('utf-8')
                st.download_button("üì• Download Labeled Dataset", csv, file_name="semi_supervised_results.csv")

        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Reinforcement Learning (Advanced)":
    with st.container():
        st.subheader("üß≠ Reinforcement Learning")
        st.caption("Simulate simple decision-making environments and watch your AI learn from feedback.")

        import numpy as np
        import matplotlib.pyplot as plt

        env_type = st.radio("Choose environment:", ["Multi-Armed Bandit", "Grid World (basic)"])
        episodes = st.slider("Episodes to run:", 10, 500, 100)

        if env_type == "Multi-Armed Bandit":
            arms = 5
            true_probs = np.random.rand(arms)
            Q = np.zeros(arms)
            N = np.zeros(arms)
            rewards = []
            epsilon = 0.1

            for ep in range(episodes):
                if np.random.rand() < epsilon:
                    action = np.random.randint(arms)
                else:
                    action = np.argmax(Q)
                reward = np.random.rand() < true_probs[action]
                N[action] += 1
                Q[action] += (reward - Q[action]) / N[action]
                rewards.append(reward)

            st.write("### Reward over episodes")
            fig, ax = plt.subplots()
            ax.plot(np.cumsum(rewards), label="Cumulative Reward")
            ax.set_xlabel("Episode")
            ax.set_ylabel("Cumulative Reward")
            st.pyplot(fig)

        elif env_type == "Grid World (basic)":
            st.write("### Grid World (3x3 Q-Learning)")
            grid_size = 3
            Q = np.zeros((grid_size, grid_size, 4))  # Up, Down, Left, Right
            rewards = np.zeros((grid_size, grid_size))
            rewards[2, 2] = 1
            gamma = 0.9
            alpha = 0.1
            epsilon = 0.1

            def step(pos, action):
                x, y = pos
                if action == 0 and y > 0: y -= 1
                elif action == 1 and y < grid_size - 1: y += 1
                elif action == 2 and x > 0: x -= 1
                elif action == 3 and x < grid_size - 1: x += 1
                return x, y

            for ep in range(episodes):
                pos = (0, 0)
                while pos != (2, 2):
                    if np.random.rand() < epsilon:
                        a = np.random.randint(4)
                    else:
                        a = np.argmax(Q[pos[0], pos[1]])
                    new_pos = step(pos, a)
                    r = rewards[new_pos]
                    best_next = np.max(Q[new_pos[0], new_pos[1]])
                    Q[pos[0], pos[1], a] += alpha * (r + gamma * best_next - Q[pos[0], pos[1], a])
                    pos = new_pos

            st.write("### Q-values (final)")
            for y in range(grid_size):
                st.text(" ".join(f"{np.max(Q[x,y]):.2f}" for x in range(grid_size)))

            fig, ax = plt.subplots()
            policy = np.argmax(Q, axis=2)
            ax.imshow(rewards, cmap="Greens", alpha=0.3)
            for i in range(grid_size):
                for j in range(grid_size):
                    action = policy[i, j]
                    arrow = ["‚Üë", "‚Üì", "‚Üê", "‚Üí"][action]
                    ax.text(j, i, arrow, ha='center', va='center', fontsize=16)
            ax.set_title("Optimal Policy (Q-learning)")
            st.pyplot(fig)

        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Descriptive Statistics":
    with st.container():
        st.subheader("üßÆ Descriptive Statistics")
        st.caption("Upload a CSV file to view summary statistics, histograms, and correlation heatmaps.")
        stat_file = st.file_uploader("Upload data file", type="csv", key="descriptive")
        use_sample = st.checkbox("Or use the Iris dataset instead")
        if stat_file or use_sample:
            import pandas as pd
            import matplotlib.pyplot as plt
            import seaborn as sns

            df = pd.read_csv(stat_file) if stat_file else pd.read_csv("https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv")
            dtype_filter = st.radio("Select column type for stats:", ["All", "Numeric Only", "Categorical Only"])
            if dtype_filter == "Numeric Only":
                df = df.select_dtypes(include=["number"])
            elif dtype_filter == "Categorical Only":
                df = df.select_dtypes(exclude=["number"])
            st.dataframe(df.head())
            st.write("### Summary Statistics")
            mode_toggle = st.checkbox("Include mode", value=False)
            percentiles = st.slider("Percentiles to show (min to max)", 0.0, 1.0, (0.25, 0.75))
            groupby_col = st.selectbox("Optional: Group stats by column", [None] + df.select_dtypes(include=["object", "category"]).columns.tolist())
            if groupby_col:
                desc = df.groupby(groupby_col).describe(percentiles=list(percentiles)).T
            else:
                desc = df.describe(percentiles=list(percentiles)).T
            if mode_toggle:
                mode_df = df.mode().iloc[0]
                desc['mode'] = mode_df
            st.dataframe(desc)

            # Export summary statistics
            csv_summary = desc.to_csv().encode('utf-8')
            st.download_button("üì• Download Summary Statistics", csv_summary, file_name="summary_stats.csv")

            if st.checkbox("Show histogram plots"):
                selected = st.multiselect("Choose columns to plot:", df.select_dtypes("number").columns.tolist())
                for col in selected:
                    fig, ax = plt.subplots()
                    df[col].hist(bins=30, ax=ax)
                    img = io.BytesIO()
                    fig.savefig(img, format='png')
                    img.seek(0)
                    st.download_button(f"üì∏ Download {col} Histogram", img.read(), file_name=f"hist_{col}.png")
                    ax.set_title(f"Histogram: {col}")
                    st.pyplot(fig)

            if st.checkbox("Show grouped bar/box plots"):
                group_col = st.selectbox("Group by (categorical column):", df.select_dtypes(include=["object", "category"]).columns.tolist())
                num_col = st.selectbox("Numeric column to visualize:", df.select_dtypes("number").columns.tolist())
                plot_type = st.radio("Plot type:", ["Bar Plot (mean)", "Box Plot"])
                import seaborn as sns
                fig, ax = plt.subplots()
                if plot_type == "Bar Plot (mean)":
                    sns.barplot(x=group_col, y=num_col, data=df, ax=ax)
                else:
                    sns.boxplot(x=group_col, y=num_col, data=df, ax=ax)
                ax.set_title(f"{plot_type} for {num_col} by {group_col}")
                st.pyplot(fig)

            if st.checkbox("Show correlation heatmap"):
                fig, ax = plt.subplots()
                sns.heatmap(df.corr(), annot=True, cmap="coolwarm", ax=ax)
                img = io.BytesIO()
                fig.savefig(img, format='png')
                img.seek(0)
                st.download_button("üì∏ Download Heatmap", img.read(), file_name="correlation_heatmap.png")
                ax.set_title("Correlation Heatmap")
                st.pyplot(fig)

        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Deep Learning Trainer":
    with st.container():
        # (Insert all content from the original Deep Learning Trainer block here)
        ...
        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Natural Language Processing (NLP)":
    with st.container():
        # (Insert all content from the original NLP expander here)
        ...
        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Image Recognition":
    with st.container():
        # (Insert all content from the original Image Recognition expander here)
        ...
        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Speech-to-Text":
    with st.container():
        # (Insert all content from the original Speech-to-Text expander here)
        ...
        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Data Analysis Workflow":
    from datetime import datetime
    st.subheader("üìò Data Analysis Workflow")
    uploaded_file = st.file_uploader("Upload your dataset (CSV)", type="csv", key="da_file")
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df.head())
        if 'price' in df.columns or 'sales' in df.columns:
            import matplotlib.pyplot as plt
            chart_col = 'price' if 'price' in df.columns else 'sales'
            fig, ax = plt.subplots()
            df[chart_col].hist(bins=30, ax=ax)
            ax.set_title(f"Histogram of {chart_col}")
            st.pyplot(fig)
        st.write("### Summary Statistics")
        st.dataframe(df.describe())
        st.write("### Data Shape")
        st.text(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")

        title = "Data Analysis"
        summary = f"Explored dataset `{uploaded_file.name}` with shape {df.shape}."
        steps = "1. Uploaded CSV
2. Reviewed summary statistics
3. Counted rows and columns"
        insights = "Spotted possible outliers and variable distributions; data types look consistent."
        conclusion = "Dataset is usable with minor preprocessing. Ready for further exploration or modeling."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        report_file = report.encode('utf-8')
        st.download_button("üìÑ Download Auto Report", report_file, file_name=f"auto_data_analysis_{datetime.now().strftime('%Y%m%d')}.txt")
    with st.container():
        st.subheader("üìò Data Analysis Workflow")
        title = "Data Analysis"
        summary = "Initial exploration and summary of uploaded dataset."
        steps = "Upload ‚Üí Summary stats ‚Üí Visualize ‚Üí Export"
        insights = "Detected outliers, skewed distribution, and strong correlation between variables."
        conclusion = "Dataset is clean and suitable for modeling. Exported clean CSV for next step."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Report as .txt", report.encode('utf-8'), file_name="data_analysis_report.txt")

elif task_selection == "Business Analysis Workflow":
    from datetime import datetime
    import pandas as pd
    st.subheader("üìä Business Analysis Workflow")
    uploaded_file = st.file_uploader("Upload your business dataset (CSV)", type="csv", key="biz_file")
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df.head())
        st.write("### KPI Metrics Overview")
        st.write(df.describe(include='all'))

        title = "Business Analysis"
        summary = f"Analyzed business dataset `{uploaded_file.name}` to identify key metrics and trends."
        steps = "1. Uploaded CSV
2. Reviewed KPIs
3. Generated summaries"
        insights = "Uncovered leading sales drivers and product performance across segments."
        conclusion = "Insights support quarterly review and targeting opportunities."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Auto Report", report.encode('utf-8'), file_name=f"auto_business_analysis_{datetime.now().strftime('%Y%m%d')}.txt")
    with st.container():
        st.subheader("üìä Business Analysis Workflow")
        title = "Business Analysis"
        summary = "Exploration of business data to uncover trends and KPIs."
        steps = "Upload ‚Üí Select metrics ‚Üí Group/Segment ‚Üí Visualize"
        insights = "Identified key revenue drivers by region and product line."
        conclusion = "Presented dashboard to stakeholders for strategic planning."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Report as .txt", report.encode('utf-8'), file_name="business_analysis_report.txt")

elif task_selection == "Data Science Workflow":
    from datetime import datetime
    import pandas as pd
    st.subheader("üî¨ Data Science Workflow")
    uploaded_file = st.file_uploader("Upload your data science dataset (CSV)", type="csv", key="ds_file")
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df.head())
        st.write("### Auto EDA Summary")
        st.dataframe(df.describe())

        title = "Data Science"
        summary = f"Performed initial EDA and preparation on dataset `{uploaded_file.name}`."
        steps = "1. Uploaded CSV
2. Ran auto-summary
3. Ready for model fitting"
        insights = "Potential feature correlations identified. Preprocessing steps outlined."
        conclusion = "Pipeline prepared for feature engineering and training."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Auto Report", report.encode('utf-8'), file_name=f"auto_data_science_{datetime.now().strftime('%Y%m%d')}.txt")
    with st.container():
        st.subheader("üî¨ Data Science Workflow")
        title = "Data Science"
        summary = "End-to-end pipeline: from EDA to ML model deployment."
        steps = "Upload ‚Üí Clean ‚Üí Feature selection ‚Üí Model ‚Üí Evaluate"
        insights = "Achieved 91% model accuracy; age and tenure were top predictors."
        conclusion = "Ready for deployment. Model exported and tested successfully."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Report as .txt", report.encode('utf-8'), file_name="data_science_report.txt")

elif task_selection == "Data Analytics Workflow":
    from datetime import datetime
    import pandas as pd
    st.subheader("üìà Data Analytics Workflow")
    uploaded_file = st.file_uploader("Upload your analytics dataset (CSV)", type="csv", key="analytics_file")
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df.head())
        st.write("### Analytics Snapshots")
        st.write(df.describe())

        title = "Data Analytics"
        summary = f"Answered business queries using data in `{uploaded_file.name}`."
        steps = "1. Uploaded CSV
2. Ran descriptive stats
3. Visual dashboards pending"
        insights = "Segment A outperformed, churn risk spotted in younger cohort."
        conclusion = "Recommended retention and conversion tactics."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Auto Report", report.encode('utf-8'), file_name=f"auto_data_analytics_{datetime.now().strftime('%Y%m%d')}.txt")
    with st.container():
        st.subheader("üìà Data Analytics Workflow")
        title = "Data Analytics"
        summary = "Answered key questions with dashboard metrics and drill-down views."
        steps = "Upload ‚Üí Query data ‚Üí Visualize ‚Üí Export dashboard"
        insights = "Top sales came from segment A; churn rate spiked in Q2."
        conclusion = "Recommended targeted campaigns and automation of report delivery."
        report = report_template(title, summary, steps, insights, conclusion)
        st.markdown(report)
        st.download_button("üìÑ Download Report as .txt", report.encode('utf-8'), file_name="data_analytics_report.txt")

elif task_selection == "Dashboards":
    with st.container():
        st.subheader("üìä Dashboards")
        st.caption("Upload a dataset and create real-time visual dashboards.")
        dash_file = st.file_uploader("Upload CSV for dashboard", type="csv", key="dash")
        if dash_file:
            import pandas as pd
            import matplotlib.pyplot as plt

            df = pd.read_csv(dash_file)
            st.dataframe(df.head())

            st.write("### Add Filters")
            for col in df.select_dtypes(include=['object', 'category']).columns:
                selected_vals = st.multiselect(f"Filter {col}:", options=df[col].unique(), default=df[col].unique())
                df = df[df[col].isin(selected_vals)]

            filtered_csv = df.to_csv(index=False).encode('utf-8')
            st.download_button("üì• Download Filtered Dataset", filtered_csv, file_name="filtered_dashboard_data.csv")
            st.write("### Dashboard Visuals")
            st.write("#### Multi-Chart Layout")
            col1, col2 = st.columns(2)
            with col1:
                st.write("##### Line Chart")
                st.line_chart(df.select_dtypes("number"))
            with col2:
                st.write("##### Area Chart")
                st.area_chart(df.select_dtypes("number"))
            chart_type = st.selectbox("Chart type:", ["Bar Chart", "Line Chart", "Area Chart"])
            num_cols = df.select_dtypes("number").columns.tolist()
            if chart_type and num_cols:
                col_x = st.selectbox("X-axis column:", df.columns.tolist())
                col_y = st.selectbox("Y-axis column:", num_cols)
                fig, ax = plt.subplots()
                if chart_type == "Bar Chart":
                    df.groupby(col_x)[col_y].mean().plot(kind='bar', ax=ax)
                elif chart_type == "Line Chart":
                    df.groupby(col_x)[col_y].mean().plot(kind='line', ax=ax)
                else:
                    df.groupby(col_x)[col_y].mean().plot(kind='area', ax=ax)
                ax.set_title(f"{chart_type}: {col_y} by {col_x}")
                st.pyplot(fig)
        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")

elif task_selection == "Time Series Analysis":
    with st.container():
        st.subheader("üìà Time Series Analysis")
        st.caption("Upload a CSV file with a datetime column and one or more numeric series to visualize and forecast.")
        ts_file = st.file_uploader("Upload time series CSV", type="csv", key="ts")
        if ts_file:
            import pandas as pd
            import matplotlib.pyplot as plt
            from pandas.plotting import register_matplotlib_converters
            from prophet import Prophet
            register_matplotlib_converters()
            df = pd.read_csv(ts_file)
            st.write(df.head())

            datetime_col = st.selectbox("Select datetime column:", df.columns)
            df[datetime_col] = pd.to_datetime(df[datetime_col])
            ts_cols = st.multiselect("Select value columns to plot:", df.select_dtypes('number').columns)

            if ts_cols:
                df.set_index(datetime_col, inplace=True)
                st.line_chart(df[ts_cols])

                if st.button("Run Prophet forecast (first column only)"):
                    ts_name = ts_cols[0]
                    prophet_df = df[[ts_name]].reset_index().rename(columns={datetime_col: "ds", ts_name: "y"})
                    st.markdown("**Seasonality options:**")
st.caption("- Daily: Captures patterns that repeat every day (e.g., hourly traffic)")
st.caption("- Weekly: Detects trends repeating every 7 days (e.g., sales on weekends)")
st.caption("- Yearly: Identifies seasonal effects across years (e.g., holidays, weather)")

daily = st.checkbox("Include daily seasonality", value=True)
                    weekly = st.checkbox("Include weekly seasonality", value=True)
                    yearly = st.checkbox("Include yearly seasonality", value=True)
                    model = Prophet(daily_seasonality=daily, weekly_seasonality=weekly, yearly_seasonality=yearly)
                    model.fit(prophet_df)
                    forecast_granularity = st.selectbox("Forecast frequency:", ["D", "W", "M"], format_func=lambda x: {"D": "Daily", "W": "Weekly", "M": "Monthly"}[x])
                    forecast_horizon = st.slider("Forecast horizon (periods):", 7, 90, 30)
                    future = model.make_future_dataframe(periods=forecast_horizon, freq=forecast_granularity)
                    forecast = model.predict(future)
                    fig = model.plot(forecast)
                    ax = fig.gca()
                    ax.plot(prophet_df['ds'], prophet_df['y'], 'k.', label='Actual')
                    ax.legend()
                    st.pyplot(fig)

                    csv = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].to_csv(index=False).encode('utf-8')
                    st.download_button("üì• Download Forecast CSV", csv, file_name="prophet_forecast.csv")

                    import io
img_buf = io.BytesIO()
fig.savefig(img_buf, format='png')
img_buf.seek(0)
st.download_button("üì∏ Download Forecast Plot Image", img_buf.read(), file_name=f"forecast_plot_{ts_name}.png")

if st.button("üìù Save this forecast session as report"):
                        report_df = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()
                        report_df['input_series'] = ts_name
                        report_df['granularity'] = forecast_granularity
                        report_df['seasonality_daily'] = daily
                        report_df['seasonality_weekly'] = weekly
                        report_df['seasonality_yearly'] = yearly

                        report_csv = report_df.to_csv(index=False).encode('utf-8')
                        st.download_button("üì• Download Session Report", report_csv, file_name=f"forecast_report_{ts_name}.csv")
        st.markdown("[üîô Back to task selector](#choose-a-task-to-explore)")
